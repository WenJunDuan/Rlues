model_provider = "custom"
model = "gpt-5.2-codex"
disable_response_storage = true
model_reasoning_effort = "xhigh"

[model_providers.custom]
name = "custom"
wire_api = "responses"
requires_openai_auth = true
base_url = ""

[mcp_servers]

[mcp_servers.memory]
type = "stdio"
command = "npx"
args = ["/c", "-y", "@modelcontextprotocol/server-memory"]
MEMORY_FILE_PATH = 'D:\workspace\mcp\server-memory\memory.json'

[mcp_servers.sequential-thinking]
type = "stdio"
command = "npx"
args = ["-y", "@modelcontextprotocol/server-sequential-thinking"]

[mcp_servers.context7]
type = "stdio"
command = "npx"
args = ["-y", "@upstash/context7-mcp"]

[mcp_servers.fetch]
type = "stdio"
command = "uvx"
args = ["mcp-server-fetch"]

[mcp_servers.fetch.env]
PYTHONIOENCODING = "utf-8"

[mcp_servers.mcp-deepwiki]
type = "stdio"
command = "npx"
args = ["-y", "mcp-deepwiki@latest"]

[mcp_servers.mcp-feedback-enhanced]
type = "stdio"
command = "uvx"
args = ["mcp-feedback-enhanced@latest"]
autoApprove = ["interactive_feedback"]
timeout = 600

[mcp_servers.augment-context-engine]
type = "stdio"
command = "auggie"
args = ["--mcp"]

[mcp_servers.augment-context-engine.env]
AUGMENT_API_TOKEN = "ace_0eff2f29e8dec9382d0ad1b46b39e587d06f6c2f"
AUGMENT_API_URL = "https://acemcp.heroman.wtf/relay/"

[mcp_servers.desktop-commander]
type = "stdio"
command = 'C:\Program Files\nodejs\npx.cmd'
args = ["-y", "@wonderwhy-er/desktop-commander"]

[mcp_servers.desktop-commander.env]
SYSTEMROOT = 'C:\\Windows'

[mcp_servers.everything]
type = "stdio"
command = "npx"
args = ["-y", "@modelcontextprotocol/server-everything"]

[mcp_servers."cunzhi"]
type = "stdio"
command = "寸止"

[mcp_servers.chrome-devtools]
type = "stdio"
command = "npx"
args = ["-y", "chrome-devtools-mcp@latest"]

[mcp_servers.promptx]
type = "stdio"
command = "npx"
args = ["-y", "@promptx/mcp-server"]
